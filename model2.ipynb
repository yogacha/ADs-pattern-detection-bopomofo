{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀檔案 & train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"data/bopomofo_interview.txt\", \"rb\") as file:   #Pickling\n",
    "    X = pickle.load(file)\n",
    "X = np.array(X)\n",
    "    \n",
    "y = pd.read_csv('data/interview_data.csv').is_ad.map({'Y': 1, 'N':0}).values\n",
    "y = np.array([1-y, y]).T  # 變換 1 -> [0, 1],  0 -> [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, stratify=y,\n",
    "                                        test_size=0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型架構\n",
    "\n",
    "這個模型事想法還是和[模型一](model1.ipynb)的特徵工程是類似的，不過不去做人為定義的特徵。\n",
    "\n",
    "模型一的特徵工程：\n",
    "\n",
    "   1. 是去尋找這段文字是中是否含有特定字眼。有則值 = 1 沒有就 = 0\n",
    "   \n",
    "\n",
    "   2. 先前的特徵我們可能允許文字的不精確性，比如：加(我)賴, `我`是可有可無的\n",
    "   \n",
    "   \n",
    "   3. 綜合這些特徵，進行最後的預測\n",
    "\n",
    "神經網路與之對應的結構：\n",
    "\n",
    "   1.  一個 filter 做 Convolution 可以視為該 filter 對應特徵的訊號強度\\\n",
    "       此時訊號強度不再是非1即0，而是一個浮點數\n",
    "      \n",
    "   \n",
    "   2. 做 Max pooling 時，較小的值不會出現在下一層。\\\n",
    "      造成時間方向(文字方向)的訊息被有條件的保留(去蕪存菁)\n",
    "   \n",
    "   \n",
    "   3. 卷積網路的最後一層 Global max pooling，是把字串不同位置，各訊號出現最強的大小保留，作為字串含有該訊號的程度。\\\n",
    "      形成字串的特徵表示，並在最後一層以 softmax 輸出，形成分類器。\n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"image/structure.png\" width=400/>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"image/lookback.png\" width=400/>\n",
    "</td> \n",
    "</table>\n",
    "\n",
    "網路的結構大致如上圖所示，輸入的 onehot 向量，先經過 embedding 得到表示一個字元的向量。然後卷積和pooling。\n",
    "\n",
    "不過有點可以注意到，max pooling(2) 會讓兩個字其中一個一定被刪除，要是剛好是兩個重要的字就糟了!\n",
    "\n",
    "所以我在這層用 stride = 1, 讓每個 pooling 的被考慮。也因為這樣，在下一層的卷積我用了 dilation = 2, 讓輸入是來自沒有重疊的 pool。\n",
    "\n",
    "使用dilation，也同時增加了最後特徵的所能尋找的原史訊號的最長長度(右圖)，最長能捕捉長度=5的字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Add, Lambda, Layer, TimeDistributed, Softmax,\\\n",
    "                         MaxPool1D, Conv1D, GlobalMaxPool1D\n",
    "from keras import Model, regularizers\n",
    "import keras.backend as K\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 41)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 5)           205       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 8)           88        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 10)          170       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inp = Input( shape=(None, 41))   # shape=(batch, time, 41)\n",
    "\n",
    "repr_vec = TimeDistributed(\n",
    "                           Dense(5,  # embedding dimension\n",
    "                                 use_bias=False,\n",
    "                                 activation='linear', \n",
    "                                 kernel_regularizer=regularizers.l2(1e-4))\n",
    "                          )(inp) \n",
    "\n",
    "cnn1 = Conv1D(8,  kernel_size=2,\n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l2(1e-4)\n",
    "             )(repr_vec)\n",
    "pool1 = MaxPool1D(pool_size=2, strides=1)(cnn1)\n",
    "\n",
    "cnn2 = Conv1D(10, kernel_size=2, dilation_rate=2, \n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l2(1e-4)\n",
    "             )(pool1)\n",
    "sentence_vec = GlobalMaxPool1D()(cnn2)\n",
    "\n",
    "out = Dense(2, activation='softmax')(sentence_vec) \n",
    "\n",
    "model = Model(inp, out)\n",
    "model.compile(optimizer=Adam(lr=0.01, beta_1=0.8), \n",
    "              loss= categorical_crossentropy,\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatch 梯度下降\n",
    "\n",
    "每次隨機抽 `200 個樣本`訓練，更新` 1 次梯度`。\n",
    "\n",
    "下一輪重抽 400 個樣本(`+200`)，以此類推...共作` 20 輪`。\n",
    "\n",
    "============================================\n",
    "\n",
    "抽部分樣本的**好處**是：\n",
    "\n",
    "   * 運算量變小，每次計算梯度的時間縮短，模型訓練較快\n",
    "\n",
    "   * 避免一次輸入過大的矩陣，造成 MemoryError。(全訓練資料是 48000 x 1500 x 41 的陣列)\n",
    "\n",
    "同時有著**缺點**：\n",
    "\n",
    "   * 抽取樣本的隨機性，若樣本不具代表性，則我們會朝錯誤的方向擬合\n",
    "\n",
    "\n",
    "對於**缺點應對**的方法：\n",
    "\n",
    "    1. 每次只更新 1 次梯度，避免過於傾向當前的 batch\n",
    "\n",
    "    2. 隨時間增加 batch size，增加 batch 的代表性。也就是梯度方向的 bias 會減小。\n",
    "\n",
    "    3. 用有動量的最佳化方法(這裡用 Adam)，前一輪的梯度方向會依例加在這一輪的梯度上。\n",
    "       就好像用前面每一個 batch 計算總梯度一樣，變象的增加 batch size 一樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7659 - acc: 0.7700\n",
      "Epoch 1/1\n",
      "400/400 [==============================] - 0s 619us/step - loss: 0.5690 - acc: 0.7500\n",
      "Epoch 1/1\n",
      "600/600 [==============================] - 1s 999us/step - loss: 0.3085 - acc: 0.8933\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1067 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1s 800us/step - loss: 0.0769 - acc: 0.9820\n",
      "Epoch 1/1\n",
      "1200/1200 [==============================] - 1s 1ms/step - loss: 0.1163 - acc: 0.9767\n",
      "Epoch 1/1\n",
      "1400/1400 [==============================] - 2s 2ms/step - loss: 0.0543 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0423 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0447 - acc: 0.9894\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0659 - acc: 0.9855\n",
      "Epoch 1/1\n",
      "2200/2200 [==============================] - 2s 1ms/step - loss: 0.0562 - acc: 0.9882\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.0636 - acc: 0.9879\n",
      "Epoch 1/1\n",
      "2600/2600 [==============================] - 2s 788us/step - loss: 0.0536 - acc: 0.9888\n",
      "Epoch 1/1\n",
      "2800/2800 [==============================] - 4s 1ms/step - loss: 0.0486 - acc: 0.9896\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0544 - acc: 0.9887\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 3s 1ms/step - loss: 0.0403 - acc: 0.9937\n",
      "Epoch 1/1\n",
      "3400/3400 [==============================] - 6s 2ms/step - loss: 0.0458 - acc: 0.9909\n",
      "Epoch 1/1\n",
      "3600/3600 [==============================] - 4s 1ms/step - loss: 0.0605 - acc: 0.9861\n",
      "Epoch 1/1\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 0.0588 - acc: 0.9882\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0396 - acc: 0.9920A: 0s - loss: 0.0402 -\n"
     ]
    }
   ],
   "source": [
    "def to3Darray(x):\n",
    "    \"\"\"Turn list of sparse Matrix into 3d Array.\"\"\"\n",
    "    maxlen = max( i.shape[0] for i in x )\n",
    "    res = np.zeros( shape=(len(x), maxlen, 41) )\n",
    "    for i, slice_ in enumerate(x):\n",
    "        res[i, :slice_.shape[0], :] = slice_.toarray()\n",
    "    return res\n",
    "\n",
    "def minibatch(size, x, y):\n",
    "    n = len(x)\n",
    "    choice = np.random.choice(np.arange(n), size, replace=False)\n",
    "    x_select = to3Darray(x[choice])\n",
    "    return x_select, y[choice, :]\n",
    "\n",
    "batch_size = 200  \n",
    "epoch = 1 # epoch for each minibatch\n",
    "\n",
    "for _ in range(20):\n",
    "    model.fit(*minibatch(batch_size, X, y), epochs=epoch) # 這裡顯示的是 batch 的 loss 和 Accuracy\n",
    "    batch_size += 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 表現\n",
    "\n",
    "* test 上表現的同樣比[樹模型](model1.ipynb)好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "12000/12000 [==============================] - 15s 1ms/step\n",
      "0.9910833239555359\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print( model.evaluate(to3Darray(X_test), y_test)[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9053,   52],\n",
       "       [  55, 2840]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix( y_test[:, 1], model.predict(to3Darray(X_test)).argmax(1) )\n",
    "# tn, fp, \n",
    "# fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 視覺化 Embedding Matrix\n",
    "\n",
    "看能不能從每個注音的表示向量觀察出甚麼有趣的事？比如我們在模型一時，相信聲母有比韻母更多資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x208e1ee7888>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Taipei Sans TC Beta']\n",
    "\n",
    "w = np.array(model.layers[1].weights[0].value() ).T\n",
    "\n",
    "plt.figure(figsize=(20, 2))\n",
    "plt.imshow(w, cmap='rainbow')\n",
    "plt.yticks([]); \n",
    "plt.xticks(range(41), [chr(i) for i in range(12549, 12586)] + ['換行', 'line', '聲調', 'Az09'])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存模型\n",
    "\n",
    "可以取消 train/test split 一樣做上面的 minibatch。應該會有更好的結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('model/cnn.h5')\n",
    "\n",
    "# with open(\"data/bopomofo_ooxx.txt\", \"rb\") as file:\n",
    "#     X = pickle.load(file)\n",
    "# X = np.array(X)\n",
    "# pred = model.predict(to3Darray(X)).argmax(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
